{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project notebook\n",
    "\n",
    "Using tensorflow and keras wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import math\n",
    "import timeit\n",
    "import matplotlib.pyplot as plt\n",
    "import utils\n",
    "import models\n",
    "import h5py\n",
    "from PIL import Image\n",
    "\n",
    "# This is a bit of magic to make matplotlib figures appear inline in the notebook\n",
    "# rather than in a new window.\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (20.0, 16.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# Some more magic so that the notebook will reload external python modules;\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Flatten, Dense, Dropout\n",
    "from keras.layers.noise import GaussianNoise\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.layers import merge\n",
    "from keras.optimizers import SGD, Adadelta, Adam, RMSprop\n",
    "from keras.utils import np_utils\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-91ba70dcfbba>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeanImage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_training_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mnum_classes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mcrop\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mX_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcrop_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcrop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcrop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/Joe/cs231n/project/utils.py\u001b[0m in \u001b[0;36mload_training_data\u001b[1;34m()\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m     \u001b[0mX_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"float64\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m     \u001b[0my_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"uint8\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mmeanImage\u001b[0m \u001b[1;33m/=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "X_train, y_train, meanImage, labels = utils.load_training_data();\n",
    "\n",
    "num_classes = len(labels);\n",
    "crop = 4; \n",
    "X_train = utils.crop_image(X_train, crop, crop);\n",
    "print(\"cropped X_train shape:\", X_train.shape)\n",
    "print(\"number of classes = \", num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Visualize some examples from the dataset.\n",
    "# We show a few examples of training images from each class.\n",
    "if crop != 0:\n",
    "    meanImageCropped = meanImage[crop:-crop, crop:-crop, :];\n",
    "else:\n",
    "    meanImageCropped = meanImage;    \n",
    "    \n",
    "classes = labels[0:10];\n",
    "num_classes = len(classes);\n",
    "samples_per_class = 7;\n",
    "for y, cls in enumerate(classes):\n",
    "    idxs = np.flatnonzero(y_train == y)\n",
    "    idxs = np.random.choice(idxs, samples_per_class, replace=False)\n",
    "    for i, idx in enumerate(idxs):\n",
    "        plt_idx = i * num_classes + y + 1\n",
    "        plt.subplot(samples_per_class, num_classes, plt_idx)\n",
    "        plt.imshow((128*X_train[idx] + meanImageCropped).astype('uint8'), interpolation=\"nearest\")\n",
    "        plt.axis('off')\n",
    "        if i == 0:\n",
    "            plt.title(cls)\n",
    "\n",
    "# mean image\n",
    "plt.figure(figsize = (5,4));\n",
    "plt.imshow(meanImage.astype('uint8'), interpolation=\"nearest\")\n",
    "plt.title('Mean image')\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_val, y_val = utils.load_validation_data(labels, meanImage);\n",
    "X_val = utils.crop_image(X_val, crop, crop);\n",
    "print(\"cropped X_val shape:\", X_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Visualize some examples from the dataset.\n",
    "# We show a few examples of training images from each class.\n",
    "plt.figure();\n",
    "for y, cls in enumerate(classes):\n",
    "    idxs = np.flatnonzero(y_val == y)\n",
    "    idxs = np.random.choice(idxs, samples_per_class, replace=False)\n",
    "    for i, idx in enumerate(idxs):\n",
    "        plt_idx = i * num_classes + y + 1\n",
    "        plt.subplot(samples_per_class, num_classes, plt_idx)\n",
    "        plt.imshow((128*X_val[idx] + meanImageCropped).astype('uint8'), interpolation=\"nearest\")\n",
    "        plt.axis('off')\n",
    "        if i == 0:\n",
    "            plt.title(cls)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load particular model saved\n",
    "# model = load_model('milestone_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# From https://gist.github.com/baraldilorenzo/07d7802847aaad0a35d3\n",
    "# model = models.VGG_16((64-2*crop, 64-2*crop, 3));\n",
    "#model = models.CNN_BN((64-2*crop, 64-2*crop, 3), drop_rate=0.75);\n",
    "#model = models.CNN64_BN(input_shape=(64, 64, 3), drop_rate=0.7);\n",
    "model = models.cnn_model3(input_shape=(64-2*crop, 64-2*crop, 3), drop_rate=0.5);\n",
    "\n",
    "#opt = SGD(lr=0.03, decay=1e-4, momentum=0.9, nesterov=True)\n",
    "#opt = RMSprop(lr=0.0005)\n",
    "opt = Adam(lr=1e-3, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "y_train_categorical = np_utils.to_categorical(y_train, num_classes=200);\n",
    "y_val_categorical = np_utils.to_categorical(y_val, num_classes=200);\n",
    "\n",
    "history = model.fit(X_train, y_train_categorical, batch_size=200, epochs=20, validation_data=(X_val, y_val_categorical), verbose=True)\n",
    "metrics = model.evaluate(X_val, y_val_categorical, verbose=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_name = 'modified_VGG16'\n",
    "weights_path = 'vgg16_weights_tf_dim_ordering_tf_kernels.h5' \n",
    "\n",
    "# Show weights in file\n",
    "f = h5py.File(weights_path)\n",
    "print([key for key in f.keys()]);\n",
    "\n",
    "# Create model\n",
    "model = models.modified_VGG16(input_shape=(64-2*crop, 64-2*crop, 3), drop_rate=0.5, stddev=1e-1);\n",
    "       \n",
    "# Load model weights from file. Only weights with existing names are loaded\n",
    "model.load_weights(weights_path, by_name=True)\n",
    "\n",
    "# Only train fully connected layers\n",
    "for i, layer in enumerate(model.layers):\n",
    "    if layer.__class__.__name__ != 'Dense':\n",
    "        model.layers[i].trainable = False;\n",
    "    \n",
    "# Show summary\n",
    "model.summary()\n",
    "\n",
    "# Train and evaluate\n",
    "opt = Adam(lr=5e-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "y_train_categorical = np_utils.to_categorical(y_train, num_classes=200);\n",
    "y_val_categorical = np_utils.to_categorical(y_val, num_classes=200);\n",
    "\n",
    "history = model.fit(X_train, y_train_categorical, batch_size=200, epochs=10, validation_data=(X_val, y_val_categorical), verbose=True)\n",
    "metrics = model.evaluate(X_val, y_val_categorical, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pylab import savefig\n",
    "\n",
    "print(history.history.keys())\n",
    "\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.ylabel('Accuracy', fontsize=20)\n",
    "plt.xlabel('epoch', fontsize=20)\n",
    "plt.legend(['Training', 'Validation'], loc='upper left')\n",
    "plt.show()\n",
    "savefig(model_name + '_accuracy.png', bbox_inches='tight')\n",
    "\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.ylabel('Loss', fontsize=20)\n",
    "plt.xlabel('epoch', fontsize=20)\n",
    "plt.legend(['Training', 'Validation'], loc='upper left')\n",
    "plt.show()\n",
    "savefig(model_name + '_loss.png', bbox_inches='tight')\n",
    "\n",
    "model.save(model_name + '_weights.h5')\n",
    "\n",
    "utils.save_historty(history.historty, model_name + '_history.txt')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Run on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load test data\n",
    "X_test, test_files = utils.load_test_data(meanImage);\n",
    "X_test = utils.crop_image(X_test, crop, crop);\n",
    "print(\"cropped X_test shape:\", X_test.shape)\n",
    "\n",
    "# Visualize some examples from the dataset.\n",
    "# We show a few examples of training images from each class.\n",
    "plt.figure();\n",
    "num_samples = 10;\n",
    "idxs = np.random.choice(range(len(test_files)), num_samples, replace=False)\n",
    "for i, idx in enumerate(idxs):\n",
    "    plt.subplot(1, num_samples, i+1)\n",
    "    plt.imshow((128*X_test[idx] + meanImageCropped).astype('uint8'), interpolation=\"nearest\")\n",
    "    plt.axis('off')\n",
    "    plt.title(test_files[idx])\n",
    "\n",
    "# Make predictions on test set\n",
    "probs = model.predict(X_test, batch_size=32, verbose=0);\n",
    "predictions = np.argmax(probs, axis=1);\n",
    "print(predictions.shape)\n",
    "\n",
    "prediceted_classes = [];\n",
    "for y in predictions:\n",
    "    prediceted_classes.append(ids[y]);\n",
    "\n",
    "# Save predictions\n",
    "utils.save_test_predictions(model_name + '_test_predictions.txt', test_files, prediceted_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
